{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jesus_Guzman_koe836_Homework3.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNOvTCpM1bi",
        "colab_type": "code",
        "outputId": "f04b36fb-1580-4222-8076-907601cc8df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.losses import mean_squared_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZih1JmQNDgg",
        "colab_type": "text"
      },
      "source": [
        "Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxWUq9SoNB_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSyYb_pDPABU",
        "colab_type": "code",
        "outputId": "21961a0b-7178-4c69-e83f-f10fdc6461de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[0][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBkjUyOQxuq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "# Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
        "    return results\n",
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OAcW9i7x2rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhHqrpJWS800",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma1k8_nJS8rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIonsKoXTgz-",
        "colab_type": "code",
        "outputId": "18052c90-696a-43a1-fe7a-2c223c852ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3190 - accuracy: 0.8776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29y7ggp6S9XZ",
        "colab_type": "text"
      },
      "source": [
        "#1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1gqxYOt2YBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvUcuoTY2qin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcgiuYqq86MF",
        "colab_type": "code",
        "outputId": "2a4a24a8-df05-4e19-e039-53eb0e02f648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B0qypugUOn7",
        "colab_type": "text"
      },
      "source": [
        "The neural network with 3 hidden layers, attained an accuracy that slightly increased from 0.8776 to 0.8778.The loss increased from 0.3190 to 0.3268. Training time remained the same, so the network with 3 hidden layers appears to be the better choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRPCuBhLkPnt",
        "colab_type": "text"
      },
      "source": [
        "#2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9elggwAtPI7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
        "model2.add(layers.Dense(32, activation='relu'))\n",
        "model2.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QL79IBKiv6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxBxTBFwi5Ck",
        "colab_type": "code",
        "outputId": "a71bdf78-28d3-41e7-ba1d-4064dc59dd7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model2.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results2 = model2.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.8738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nYeuRYc7xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = models.Sequential()\n",
        "model3.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model3.add(layers.Dense(64, activation='relu'))\n",
        "model3.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4V9nDFtkKSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swwIjCYrkKmU",
        "colab_type": "code",
        "outputId": "5e70806b-433c-4f6f-b9c6-2b7a69ef3424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model3.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results3 = model3.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o15oumNtW-xp",
        "colab_type": "text"
      },
      "source": [
        "The fist model attained a better accuracy and loss score, than the model2 and model3. Model2 has the same number of hidden layers, but it has 32 hidden units. The accuracy decreased from .8776 to .8656. The loss increased from \n",
        ".3190 to .3806. The runtime was remained the same for model2, but it slightly increased for model3. Similar to the second model, model3 with 64 hidden units performed worse than the original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkrh9xXswzrV",
        "colab_type": "text"
      },
      "source": [
        "#3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpujgBFHnKfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4= models.Sequential()\n",
        "model4.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model4.add(layers.Dense(16, activation='relu'))\n",
        "model4.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_vipdCbk2Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4.compile(optimizer='rmsprop',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRFutenBlOzD",
        "colab_type": "code",
        "outputId": "a36a1816-fa3a-43a1-cb19-566e8283ae29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model4.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results4 = model4.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.8803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHk60TN9XBmK",
        "colab_type": "text"
      },
      "source": [
        "Runtime is the same for this model and the original one. The loss is .0884 as compared to the first model with a loss of .3190. The accuracy is slighly better for the fourth model, since it change from .8776 to .8803. It seems that changing the loss to mse will help the model perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctClGWNOw3F0",
        "colab_type": "text"
      },
      "source": [
        "#4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CrBTVZ_f7C7s",
        "colab": {}
      },
      "source": [
        "model5 = models.Sequential()\n",
        "model5.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
        "model5.add(layers.Dense(16, activation='tanh'))\n",
        "model5.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQqOh_ZD7C78",
        "colab": {}
      },
      "source": [
        "model5.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmiwBzxv5z_9",
        "colab_type": "code",
        "outputId": "db5b12f7-5960-4230-83c2-ccf8f1efe70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model5.fit(x_train, y_train, epochs=5, batch_size=512, verbose = 0)\n",
        "results5 = model5.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuizlTIIpUW9",
        "colab_type": "text"
      },
      "source": [
        "Runtime did not change from the first to the fifth model. Accuracy decreased from .8776 to .8741, and loss increased from .3190 to .3456. The first model outperforms this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbef98ZhQBnP",
        "colab_type": "text"
      },
      "source": [
        "Problem 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vlXLDyAQGZy",
        "colab_type": "text"
      },
      "source": [
        "#1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bwMO1UjQFBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "car = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data',\n",
        "                  sep =' ',\n",
        "                  na_values = '?',\n",
        "                  names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin','car_name'],\n",
        "                  skipinitialspace = True,\n",
        "                  comment = '\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qw-iKiGRX6k",
        "colab_type": "code",
        "outputId": "2fb49111-b907-4c6a-8285-6be3c3bba841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "car.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ...  model_year  origin  car_name\n",
              "0  18.0          8         307.0  ...          70       1       NaN\n",
              "1  15.0          8         350.0  ...          70       1       NaN\n",
              "2  18.0          8         318.0  ...          70       1       NaN\n",
              "3  16.0          8         304.0  ...          70       1       NaN\n",
              "4  17.0          8         302.0  ...          70       1       NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyQXhrxxTMqr",
        "colab_type": "code",
        "outputId": "81ba8a49-f06c-4c68-c32c-4472a8421907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "car = car.drop('car_name', axis=1)\n",
        "car.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavWIwOgYFjw",
        "colab_type": "code",
        "outputId": "96cc4bba-5b92-4baf-d472-6c8b233b407f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "car.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    392 non-null    float64\n",
            " 4   weight        398 non-null    float64\n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model_year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 25.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f289JmYSsty",
        "colab_type": "code",
        "outputId": "eec834d4-27bb-4725-b06f-eb5dafa02ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "car.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      6\n",
              "weight          0\n",
              "acceleration    0\n",
              "model_year      0\n",
              "origin          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzfFU8a7TGhV",
        "colab_type": "code",
        "outputId": "a5628ad5-dc9b-41d2-e4e8-cc291ab45809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "car.dropna(inplace=True)\n",
        "car.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      0\n",
              "weight          0\n",
              "acceleration    0\n",
              "model_year      0\n",
              "origin          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wutloZeX7Op",
        "colab_type": "code",
        "outputId": "f43637cd-b7bb-4899-e7e9-791c1a2ef596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "car.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 392 entries, 0 to 397\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           392 non-null    float64\n",
            " 1   cylinders     392 non-null    int64  \n",
            " 2   displacement  392 non-null    float64\n",
            " 3   horsepower    392 non-null    float64\n",
            " 4   weight        392 non-null    float64\n",
            " 5   acceleration  392 non-null    float64\n",
            " 6   model_year    392 non-null    int64  \n",
            " 7   origin        392 non-null    int64  \n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 27.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTDygkwxYQAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_car = pd.get_dummies(car, columns=[\"origin\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDhZljw2YfR4",
        "colab_type": "code",
        "outputId": "0c9ecd8c-c4fb-4e14-c564-b86e609360aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "new_car.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin_1</th>\n",
              "      <th>origin_2</th>\n",
              "      <th>origin_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ...  origin_1  origin_2  origin_3\n",
              "0  18.0          8         307.0  ...         1         0         0\n",
              "1  15.0          8         350.0  ...         1         0         0\n",
              "2  18.0          8         318.0  ...         1         0         0\n",
              "3  16.0          8         304.0  ...         1         0         0\n",
              "4  17.0          8         302.0  ...         1         0         0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw2_xAaiY_Qr",
        "colab_type": "text"
      },
      "source": [
        "# 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022QpyB0Z3lu",
        "colab_type": "code",
        "outputId": "18222803-7a43-4f93-fa80-d86999d21022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_car = new_car['mpg']\n",
        "Y_car.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(392,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWYcoOT5aJ3b",
        "colab_type": "code",
        "outputId": "962c2332-a286-4711-8f2f-46ec3cd25a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_car = new_car.drop('mpg', axis = 1)\n",
        "X_car.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(392, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YczlbbiWWBVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X_car, Y_car, random_state = 1, train_size = 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR7W_S3jv8Sv",
        "colab_type": "text"
      },
      "source": [
        "#3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JulZ9DF4Zymh",
        "colab_type": "code",
        "outputId": "b930cbe7-ff69-4cfb-d42a-76a2475d4510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "new_car.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin_1</th>\n",
              "      <th>origin_2</th>\n",
              "      <th>origin_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.445918</td>\n",
              "      <td>5.471939</td>\n",
              "      <td>194.411990</td>\n",
              "      <td>104.469388</td>\n",
              "      <td>2977.584184</td>\n",
              "      <td>15.541327</td>\n",
              "      <td>75.979592</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.173469</td>\n",
              "      <td>0.201531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.805007</td>\n",
              "      <td>1.705783</td>\n",
              "      <td>104.644004</td>\n",
              "      <td>38.491160</td>\n",
              "      <td>849.402560</td>\n",
              "      <td>2.758864</td>\n",
              "      <td>3.683737</td>\n",
              "      <td>0.484742</td>\n",
              "      <td>0.379136</td>\n",
              "      <td>0.401656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>1613.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2225.250000</td>\n",
              "      <td>13.775000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>2803.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>275.750000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>3614.750000</td>\n",
              "      <td>17.025000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>46.600000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>5140.000000</td>\n",
              "      <td>24.800000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              mpg   cylinders  displacement  ...    origin_1    origin_2    origin_3\n",
              "count  392.000000  392.000000    392.000000  ...  392.000000  392.000000  392.000000\n",
              "mean    23.445918    5.471939    194.411990  ...    0.625000    0.173469    0.201531\n",
              "std      7.805007    1.705783    104.644004  ...    0.484742    0.379136    0.401656\n",
              "min      9.000000    3.000000     68.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     17.000000    4.000000    105.000000  ...    0.000000    0.000000    0.000000\n",
              "50%     22.750000    4.000000    151.000000  ...    1.000000    0.000000    0.000000\n",
              "75%     29.000000    8.000000    275.750000  ...    1.000000    0.000000    0.000000\n",
              "max     46.600000    8.000000    455.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xyZ80PZEkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = Xtrain.mean(axis=0)\n",
        "Xtrain -= mean\n",
        "std = Xtrain.std(axis=0)\n",
        "Xtrain /= std\n",
        "\n",
        "Xtest -= mean\n",
        "Xtest /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSHmrbUtxBxT",
        "colab_type": "text"
      },
      "source": [
        "#4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIdCn85wE3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelc = models.Sequential()\n",
        "modelc.add(layers.Dense(32, activation='relu',input_shape=(Xtrain.shape[1],)))\n",
        "modelc.add(layers.Dense(32, activation='relu'))\n",
        "modelc.add(layers.Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suDx_sZ7bGtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelc.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzwicUjjxEJ6",
        "colab_type": "text"
      },
      "source": [
        "#5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK5X-zR3bh8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xval, par_x_train = np.split(Xtrain, [int(0.2 * len(Xtrain))])\n",
        "yval, par_y_train = np.split(ytrain, [int(0.2 * len(ytrain))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KVVaQvb9Zq",
        "colab_type": "code",
        "outputId": "583a8cc6-7546-40b1-93a7-9708962df6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yval.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Rl0nT6b4OH",
        "colab_type": "code",
        "outputId": "00a7b994-021c-4743-d028-21110c671c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xval.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffZlsEVEcA3Z",
        "colab_type": "code",
        "outputId": "4a41b3ba-594b-4e42-9f28-3fb558655b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "par_y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vzlVPV0cAz_",
        "colab_type": "code",
        "outputId": "eddc2852-1195-446e-8166-9f95d5af9900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "par_x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XbSW8_3cPgr",
        "colab_type": "code",
        "outputId": "3ce364fc-d6d8-4a85-ce36-2242eef84a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "historyc = modelc.fit(par_x_train,\n",
        "                    par_y_train,\n",
        "                    epochs=500,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(xval, yval))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 580.0864 - mae: 22.6716 - val_loss: 533.0598 - val_mae: 21.7298\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 491.5183 - mae: 20.8349 - val_loss: 448.2275 - val_mae: 19.5558\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 398.2892 - mae: 18.3437 - val_loss: 344.2928 - val_mae: 16.6602\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 295.1903 - mae: 15.4007 - val_loss: 236.1236 - val_mae: 13.4402\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 192.4304 - mae: 12.1730 - val_loss: 127.9815 - val_mae: 9.7864\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 94.2468 - mae: 8.4376 - val_loss: 52.3653 - val_mae: 6.1252\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 36.4546 - mae: 4.9315 - val_loss: 25.2914 - val_mae: 4.0654\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 19.8587 - mae: 3.5624 - val_loss: 18.9470 - val_mae: 3.4000\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 15.6651 - mae: 3.0857 - val_loss: 16.3086 - val_mae: 3.1815\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 14.1866 - mae: 2.8756 - val_loss: 13.8276 - val_mae: 2.9282\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 12.1733 - mae: 2.7087 - val_loss: 13.1891 - val_mae: 2.9041\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 11.3572 - mae: 2.5634 - val_loss: 11.6339 - val_mae: 2.7056\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 10.8030 - mae: 2.4743 - val_loss: 11.2960 - val_mae: 2.7110\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5435 - mae: 2.3553 - val_loss: 10.1347 - val_mae: 2.5323\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9292 - mae: 2.2789 - val_loss: 9.3838 - val_mae: 2.4368\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5402 - mae: 2.2108 - val_loss: 9.8131 - val_mae: 2.4891\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1481 - mae: 2.1231 - val_loss: 9.4171 - val_mae: 2.4458\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7714 - mae: 2.0598 - val_loss: 9.1755 - val_mae: 2.3581\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5673 - mae: 2.0257 - val_loss: 8.6522 - val_mae: 2.3253\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0706 - mae: 1.9893 - val_loss: 9.1868 - val_mae: 2.3735\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9384 - mae: 1.9487 - val_loss: 8.3972 - val_mae: 2.2604\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6595 - mae: 1.9216 - val_loss: 8.3429 - val_mae: 2.2292\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4358 - mae: 1.8733 - val_loss: 8.0677 - val_mae: 2.1582\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6924 - mae: 1.8822 - val_loss: 8.4697 - val_mae: 2.2149\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1271 - mae: 1.8303 - val_loss: 8.6098 - val_mae: 2.1876\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2114 - mae: 1.8457 - val_loss: 8.1574 - val_mae: 2.1759\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0363 - mae: 1.8427 - val_loss: 7.9625 - val_mae: 2.1369\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8463 - mae: 1.8033 - val_loss: 9.3573 - val_mae: 2.2940\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1239 - mae: 1.8314 - val_loss: 8.7670 - val_mae: 2.2000\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9132 - mae: 1.8122 - val_loss: 8.5398 - val_mae: 2.1824\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8186 - mae: 1.8155 - val_loss: 8.1295 - val_mae: 2.1144\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8608 - mae: 1.8112 - val_loss: 8.0525 - val_mae: 2.1251\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9987 - mae: 1.7710 - val_loss: 8.5489 - val_mae: 2.2050\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7203 - mae: 1.7893 - val_loss: 7.7526 - val_mae: 2.0874\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6680 - mae: 1.7880 - val_loss: 7.9328 - val_mae: 2.1091\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7051 - mae: 1.7322 - val_loss: 8.2216 - val_mae: 2.1818\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6806 - mae: 1.7793 - val_loss: 8.5230 - val_mae: 2.1672\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7625 - mae: 1.7602 - val_loss: 8.8647 - val_mae: 2.1904\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5384 - mae: 1.7559 - val_loss: 8.7354 - val_mae: 2.1985\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6287 - mae: 1.7408 - val_loss: 8.4876 - val_mae: 2.1614\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0070 - mae: 1.7470 - val_loss: 8.1901 - val_mae: 2.1308\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.3955 - mae: 1.7395 - val_loss: 8.5007 - val_mae: 2.1734\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2963 - mae: 1.7083 - val_loss: 8.0127 - val_mae: 2.0543\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3790 - mae: 1.7257 - val_loss: 8.0462 - val_mae: 2.0512\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3373 - mae: 1.7269 - val_loss: 8.8368 - val_mae: 2.2244\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3401 - mae: 1.7300 - val_loss: 9.0893 - val_mae: 2.2462\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2609 - mae: 1.7351 - val_loss: 8.3533 - val_mae: 2.1148\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3834 - mae: 1.7446 - val_loss: 8.4199 - val_mae: 2.1465\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3206 - mae: 1.7445 - val_loss: 8.5314 - val_mae: 2.1628\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1888 - mae: 1.7101 - val_loss: 8.1139 - val_mae: 2.0782\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2209 - mae: 1.7226 - val_loss: 8.5078 - val_mae: 2.1560\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1787 - mae: 1.7275 - val_loss: 8.2559 - val_mae: 2.0896\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1403 - mae: 1.6965 - val_loss: 8.1394 - val_mae: 2.0660\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1952 - mae: 1.7084 - val_loss: 8.7212 - val_mae: 2.1864\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1781 - mae: 1.6904 - val_loss: 8.5240 - val_mae: 2.1535\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0313 - mae: 1.7132 - val_loss: 9.2711 - val_mae: 2.2759\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1324 - mae: 1.7133 - val_loss: 8.4757 - val_mae: 2.1298\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1424 - mae: 1.7046 - val_loss: 8.6472 - val_mae: 2.2062\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0429 - mae: 1.6903 - val_loss: 8.8454 - val_mae: 2.2228\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1072 - mae: 1.6861 - val_loss: 8.2695 - val_mae: 2.0758\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0282 - mae: 1.6827 - val_loss: 8.0618 - val_mae: 2.0364\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0707 - mae: 1.6899 - val_loss: 8.4473 - val_mae: 2.1304\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.9647 - mae: 1.6694 - val_loss: 8.4487 - val_mae: 2.1254\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8454 - mae: 1.6492 - val_loss: 8.6789 - val_mae: 2.2114\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9757 - mae: 1.6620 - val_loss: 8.2909 - val_mae: 2.0553\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8941 - mae: 1.6570 - val_loss: 8.1087 - val_mae: 2.0625\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8256 - mae: 1.6418 - val_loss: 9.2309 - val_mae: 2.2637\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9817 - mae: 1.6823 - val_loss: 8.1256 - val_mae: 2.0545\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9531 - mae: 1.6764 - val_loss: 8.2185 - val_mae: 2.0720\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0183 - mae: 1.6695 - val_loss: 8.2767 - val_mae: 2.0748\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8037 - mae: 1.6304 - val_loss: 9.0452 - val_mae: 2.2556\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.7602 - mae: 1.6630 - val_loss: 9.5505 - val_mae: 2.3352\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8647 - mae: 1.6564 - val_loss: 8.5601 - val_mae: 2.1478\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9023 - mae: 1.6490 - val_loss: 8.3917 - val_mae: 2.1153\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9292 - mae: 1.6404 - val_loss: 8.2768 - val_mae: 2.0792\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7779 - mae: 1.6362 - val_loss: 8.4459 - val_mae: 2.1087\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7883 - mae: 1.6632 - val_loss: 8.6438 - val_mae: 2.1698\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7948 - mae: 1.6527 - val_loss: 8.5967 - val_mae: 2.1492\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7550 - mae: 1.6323 - val_loss: 8.3262 - val_mae: 2.0773\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0175 - mae: 1.6109 - val_loss: 8.7717 - val_mae: 2.1922\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8222 - mae: 1.6178 - val_loss: 8.8174 - val_mae: 2.1839\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6006 - mae: 1.6302 - val_loss: 8.7262 - val_mae: 2.1881\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8339 - mae: 1.6423 - val_loss: 8.3574 - val_mae: 2.0956\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8657 - mae: 1.6015 - val_loss: 8.7031 - val_mae: 2.2002\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6127 - mae: 1.6173 - val_loss: 8.7728 - val_mae: 2.2185\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8866 - mae: 1.5953 - val_loss: 8.4741 - val_mae: 2.1392\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7909 - mae: 1.6191 - val_loss: 8.3702 - val_mae: 2.0756\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6648 - mae: 1.6243 - val_loss: 8.4357 - val_mae: 2.1243\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5948 - mae: 1.6087 - val_loss: 8.8217 - val_mae: 2.2227\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6819 - mae: 1.6012 - val_loss: 8.2590 - val_mae: 2.0375\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6478 - mae: 1.6348 - val_loss: 8.2430 - val_mae: 2.0635\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5932 - mae: 1.6064 - val_loss: 8.5731 - val_mae: 2.1701\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5845 - mae: 1.5889 - val_loss: 8.7285 - val_mae: 2.2009\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7283 - mae: 1.5877 - val_loss: 8.3886 - val_mae: 2.1218\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5730 - mae: 1.5665 - val_loss: 9.8797 - val_mae: 2.4702\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3811 - mae: 1.5875 - val_loss: 8.2942 - val_mae: 2.0574\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6821 - mae: 1.5747 - val_loss: 8.5110 - val_mae: 2.1574\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6554 - mae: 1.5984 - val_loss: 8.3236 - val_mae: 2.0952\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4491 - mae: 1.5842 - val_loss: 9.3897 - val_mae: 2.3177\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6159 - mae: 1.5886 - val_loss: 8.7831 - val_mae: 2.2111\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4379 - mae: 1.5846 - val_loss: 8.3207 - val_mae: 2.0628\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5743 - mae: 1.6030 - val_loss: 8.4366 - val_mae: 2.1152\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4096 - mae: 1.5596 - val_loss: 8.2981 - val_mae: 2.0434\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6452 - mae: 1.6193 - val_loss: 8.4296 - val_mae: 2.1315\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4859 - mae: 1.5775 - val_loss: 9.3041 - val_mae: 2.3247\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4226 - mae: 1.5603 - val_loss: 8.8844 - val_mae: 2.2259\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4183 - mae: 1.5640 - val_loss: 8.7350 - val_mae: 2.2045\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3921 - mae: 1.5869 - val_loss: 8.2406 - val_mae: 2.0431\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4643 - mae: 1.5701 - val_loss: 8.6963 - val_mae: 2.1914\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5774 - mae: 1.5852 - val_loss: 9.2506 - val_mae: 2.2794\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4025 - mae: 1.5546 - val_loss: 9.8108 - val_mae: 2.4000\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3941 - mae: 1.5780 - val_loss: 8.4904 - val_mae: 2.1281\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3256 - mae: 1.5396 - val_loss: 8.8351 - val_mae: 2.2341\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5143 - mae: 1.5585 - val_loss: 8.8212 - val_mae: 2.2230\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4766 - mae: 1.5409 - val_loss: 8.4457 - val_mae: 2.1152\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4459 - mae: 1.5333 - val_loss: 9.0945 - val_mae: 2.2696\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2832 - mae: 1.5480 - val_loss: 9.2272 - val_mae: 2.3395\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3801 - mae: 1.5542 - val_loss: 9.0700 - val_mae: 2.2752\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6419 - mae: 1.5592 - val_loss: 9.1510 - val_mae: 2.2798\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2446 - mae: 1.5589 - val_loss: 9.4614 - val_mae: 2.3572\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4112 - mae: 1.5524 - val_loss: 8.4135 - val_mae: 2.1116\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4250 - mae: 1.5685 - val_loss: 9.2398 - val_mae: 2.3071\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3606 - mae: 1.5327 - val_loss: 9.3029 - val_mae: 2.3035\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2388 - mae: 1.5405 - val_loss: 10.5504 - val_mae: 2.4623\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3354 - mae: 1.5401 - val_loss: 9.0391 - val_mae: 2.3002\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4007 - mae: 1.5048 - val_loss: 8.4834 - val_mae: 2.1431\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2334 - mae: 1.5288 - val_loss: 8.5616 - val_mae: 2.1664\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1384 - mae: 1.5376 - val_loss: 8.7568 - val_mae: 2.1088\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5810 - mae: 1.5256 - val_loss: 10.0366 - val_mae: 2.4236\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1996 - mae: 1.5228 - val_loss: 8.5537 - val_mae: 2.1440\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4095 - mae: 1.5195 - val_loss: 9.5941 - val_mae: 2.3518\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2379 - mae: 1.5361 - val_loss: 8.7354 - val_mae: 2.2016\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3022 - mae: 1.5142 - val_loss: 8.5557 - val_mae: 2.1643\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1290 - mae: 1.4931 - val_loss: 9.7285 - val_mae: 2.3705\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2051 - mae: 1.5270 - val_loss: 8.4817 - val_mae: 2.0656\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2540 - mae: 1.5465 - val_loss: 9.1333 - val_mae: 2.2998\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3562 - mae: 1.5183 - val_loss: 8.7424 - val_mae: 2.2002\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2942 - mae: 1.5301 - val_loss: 8.6047 - val_mae: 2.1759\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1891 - mae: 1.4982 - val_loss: 8.9130 - val_mae: 2.2473\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2610 - mae: 1.5231 - val_loss: 8.5467 - val_mae: 2.1681\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0767 - mae: 1.5192 - val_loss: 8.7190 - val_mae: 2.2046\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1834 - mae: 1.5225 - val_loss: 8.5156 - val_mae: 2.1305\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0668 - mae: 1.5079 - val_loss: 9.1842 - val_mae: 2.3229\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1118 - mae: 1.5154 - val_loss: 8.8242 - val_mae: 2.2413\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0505 - mae: 1.4977 - val_loss: 8.7724 - val_mae: 2.2404\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9496 - mae: 1.4572 - val_loss: 9.7279 - val_mae: 2.3689\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0535 - mae: 1.4915 - val_loss: 8.6037 - val_mae: 2.1572\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0737 - mae: 1.5150 - val_loss: 8.7491 - val_mae: 2.1954\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0602 - mae: 1.4878 - val_loss: 9.4168 - val_mae: 2.3527\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0978 - mae: 1.4990 - val_loss: 8.7919 - val_mae: 2.2015\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0733 - mae: 1.4766 - val_loss: 8.7468 - val_mae: 2.1748\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0369 - mae: 1.4918 - val_loss: 8.9657 - val_mae: 2.2391\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0639 - mae: 1.4993 - val_loss: 8.8508 - val_mae: 2.2067\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9914 - mae: 1.4552 - val_loss: 8.5355 - val_mae: 2.0733\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0301 - mae: 1.4401 - val_loss: 8.7980 - val_mae: 2.2074\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3547 - mae: 1.4808 - val_loss: 8.9263 - val_mae: 2.2234\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9315 - mae: 1.4769 - val_loss: 8.9059 - val_mae: 2.2237\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9026 - mae: 1.4301 - val_loss: 9.4492 - val_mae: 2.3296\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9458 - mae: 1.4886 - val_loss: 9.3149 - val_mae: 2.3065\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9973 - mae: 1.4863 - val_loss: 9.0569 - val_mae: 2.2636\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0624 - mae: 1.4926 - val_loss: 8.8250 - val_mae: 2.1950\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8526 - mae: 1.4663 - val_loss: 8.8765 - val_mae: 2.2049\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9954 - mae: 1.4642 - val_loss: 8.7249 - val_mae: 2.1676\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2297 - mae: 1.4796 - val_loss: 8.7379 - val_mae: 2.1529\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9197 - mae: 1.4556 - val_loss: 8.6389 - val_mae: 2.1503\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8449 - mae: 1.4772 - val_loss: 9.3354 - val_mae: 2.3018\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9562 - mae: 1.4667 - val_loss: 9.0653 - val_mae: 2.2651\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9562 - mae: 1.4363 - val_loss: 9.1177 - val_mae: 2.2734\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8497 - mae: 1.4477 - val_loss: 8.8261 - val_mae: 2.1772\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9814 - mae: 1.4734 - val_loss: 9.0140 - val_mae: 2.2007\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0054 - mae: 1.4630 - val_loss: 9.5689 - val_mae: 2.3761\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8938 - mae: 1.4705 - val_loss: 8.8472 - val_mae: 2.2037\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9141 - mae: 1.4614 - val_loss: 9.1950 - val_mae: 2.2757\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8851 - mae: 1.4320 - val_loss: 9.0456 - val_mae: 2.2517\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9955 - mae: 1.4677 - val_loss: 8.8950 - val_mae: 2.1266\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9137 - mae: 1.4051 - val_loss: 9.3909 - val_mae: 2.3031\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8316 - mae: 1.4518 - val_loss: 9.9030 - val_mae: 2.4417\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9218 - mae: 1.4348 - val_loss: 8.9815 - val_mae: 2.2272\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7955 - mae: 1.4367 - val_loss: 9.1162 - val_mae: 2.2675\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8030 - mae: 1.4122 - val_loss: 8.7103 - val_mae: 2.1795\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7635 - mae: 1.4098 - val_loss: 8.9907 - val_mae: 2.2447\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8937 - mae: 1.4276 - val_loss: 9.2100 - val_mae: 2.3030\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8446 - mae: 1.4365 - val_loss: 9.7850 - val_mae: 2.3975\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7078 - mae: 1.4109 - val_loss: 9.0535 - val_mae: 2.2553\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7480 - mae: 1.3705 - val_loss: 8.9060 - val_mae: 2.2243\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9186 - mae: 1.4263 - val_loss: 10.2806 - val_mae: 2.4821\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7146 - mae: 1.4092 - val_loss: 8.7772 - val_mae: 2.1665\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7543 - mae: 1.4236 - val_loss: 9.5036 - val_mae: 2.3660\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8174 - mae: 1.4222 - val_loss: 8.9993 - val_mae: 2.2484\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7648 - mae: 1.4120 - val_loss: 8.9159 - val_mae: 2.2297\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8759 - mae: 1.4417 - val_loss: 9.2171 - val_mae: 2.3254\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7290 - mae: 1.4066 - val_loss: 9.1891 - val_mae: 2.3062\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6482 - mae: 1.4132 - val_loss: 8.8866 - val_mae: 2.0811\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7892 - mae: 1.4148 - val_loss: 9.2072 - val_mae: 2.3117\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7440 - mae: 1.4054 - val_loss: 9.5203 - val_mae: 2.3555\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7949 - mae: 1.4264 - val_loss: 9.3773 - val_mae: 2.3156\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6083 - mae: 1.4013 - val_loss: 8.9758 - val_mae: 2.2358\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7967 - mae: 1.4063 - val_loss: 9.0952 - val_mae: 2.2584\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7122 - mae: 1.4045 - val_loss: 9.2689 - val_mae: 2.2880\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8837 - mae: 1.4169 - val_loss: 9.0596 - val_mae: 2.2445\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0203 - mae: 1.3907 - val_loss: 9.1637 - val_mae: 2.2761\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7051 - mae: 1.3944 - val_loss: 9.0675 - val_mae: 2.2653\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6206 - mae: 1.3797 - val_loss: 9.0909 - val_mae: 2.2502\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6813 - mae: 1.3878 - val_loss: 9.3819 - val_mae: 2.3631\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7291 - mae: 1.3955 - val_loss: 8.9056 - val_mae: 2.1648\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6378 - mae: 1.3949 - val_loss: 8.9344 - val_mae: 2.2140\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7213 - mae: 1.3834 - val_loss: 9.0313 - val_mae: 2.1556\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6739 - mae: 1.3949 - val_loss: 9.3144 - val_mae: 2.2785\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7011 - mae: 1.4119 - val_loss: 9.1037 - val_mae: 2.2487\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7448 - mae: 1.4020 - val_loss: 9.0039 - val_mae: 2.1621\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6955 - mae: 1.3911 - val_loss: 9.6479 - val_mae: 2.3741\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7332 - mae: 1.4004 - val_loss: 9.1862 - val_mae: 2.1817\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5308 - mae: 1.3918 - val_loss: 10.0023 - val_mae: 2.4176\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6559 - mae: 1.4037 - val_loss: 10.1403 - val_mae: 2.4466\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6025 - mae: 1.4063 - val_loss: 9.8751 - val_mae: 2.4130\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6067 - mae: 1.3819 - val_loss: 9.5071 - val_mae: 2.3170\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6050 - mae: 1.3623 - val_loss: 9.0475 - val_mae: 2.2018\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6360 - mae: 1.3600 - val_loss: 10.3368 - val_mae: 2.4443\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8082 - mae: 1.3901 - val_loss: 9.2271 - val_mae: 2.2009\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5118 - mae: 1.3596 - val_loss: 9.6365 - val_mae: 2.3173\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5848 - mae: 1.3793 - val_loss: 9.0940 - val_mae: 2.2210\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5640 - mae: 1.3507 - val_loss: 9.3625 - val_mae: 2.2865\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4379 - mae: 1.3620 - val_loss: 9.3065 - val_mae: 2.1791\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5400 - mae: 1.3756 - val_loss: 9.1845 - val_mae: 2.2142\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5717 - mae: 1.3543 - val_loss: 9.5522 - val_mae: 2.3174\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5769 - mae: 1.3609 - val_loss: 10.5018 - val_mae: 2.5162\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5991 - mae: 1.3610 - val_loss: 9.5441 - val_mae: 2.3081\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5222 - mae: 1.3533 - val_loss: 9.2058 - val_mae: 2.2216\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5702 - mae: 1.3684 - val_loss: 9.7875 - val_mae: 2.3731\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.5044 - mae: 1.3602 - val_loss: 10.0417 - val_mae: 2.4221\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4595 - mae: 1.3464 - val_loss: 9.5882 - val_mae: 2.2680\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5775 - mae: 1.3884 - val_loss: 9.7444 - val_mae: 2.3580\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4997 - mae: 1.3372 - val_loss: 10.6412 - val_mae: 2.4834\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4637 - mae: 1.3510 - val_loss: 11.0464 - val_mae: 2.5711\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4374 - mae: 1.3271 - val_loss: 9.7422 - val_mae: 2.3837\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4939 - mae: 1.3398 - val_loss: 10.1154 - val_mae: 2.4175\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4455 - mae: 1.3340 - val_loss: 9.7283 - val_mae: 2.3614\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4061 - mae: 1.3146 - val_loss: 10.2185 - val_mae: 2.4472\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5350 - mae: 1.3442 - val_loss: 10.2588 - val_mae: 2.4271\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4210 - mae: 1.3348 - val_loss: 9.6530 - val_mae: 2.3359\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4430 - mae: 1.3469 - val_loss: 10.2174 - val_mae: 2.4392\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4903 - mae: 1.3333 - val_loss: 9.4449 - val_mae: 2.2986\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3395 - mae: 1.3268 - val_loss: 10.5601 - val_mae: 2.5295\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4443 - mae: 1.3575 - val_loss: 9.6156 - val_mae: 2.3188\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4971 - mae: 1.3269 - val_loss: 10.1041 - val_mae: 2.3789\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6188 - mae: 1.3033 - val_loss: 9.5026 - val_mae: 2.2652\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4652 - mae: 1.3348 - val_loss: 10.9064 - val_mae: 2.5453\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5474 - mae: 1.3185 - val_loss: 9.5560 - val_mae: 2.2834\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3110 - mae: 1.2972 - val_loss: 11.4792 - val_mae: 2.5614\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3904 - mae: 1.3226 - val_loss: 10.3854 - val_mae: 2.4198\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4188 - mae: 1.3243 - val_loss: 10.0107 - val_mae: 2.3674\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3782 - mae: 1.3136 - val_loss: 10.5627 - val_mae: 2.5114\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6906 - mae: 1.3430 - val_loss: 9.4986 - val_mae: 2.2049\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5413 - mae: 1.3394 - val_loss: 9.8067 - val_mae: 2.3171\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2774 - mae: 1.2969 - val_loss: 11.0537 - val_mae: 2.5457\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3506 - mae: 1.3363 - val_loss: 11.0725 - val_mae: 2.5434\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3962 - mae: 1.3276 - val_loss: 9.9152 - val_mae: 2.3429\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4001 - mae: 1.2980 - val_loss: 9.4911 - val_mae: 2.2497\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3169 - mae: 1.2966 - val_loss: 10.1351 - val_mae: 2.3542\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2797 - mae: 1.3141 - val_loss: 9.4687 - val_mae: 2.1956\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3959 - mae: 1.3066 - val_loss: 10.1225 - val_mae: 2.3748\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2943 - mae: 1.2923 - val_loss: 11.5501 - val_mae: 2.6069\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3314 - mae: 1.2953 - val_loss: 11.6913 - val_mae: 2.6337\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3576 - mae: 1.3102 - val_loss: 9.6956 - val_mae: 2.2874\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4207 - mae: 1.3151 - val_loss: 11.2249 - val_mae: 2.5774\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3517 - mae: 1.3117 - val_loss: 9.9050 - val_mae: 2.3171\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3194 - mae: 1.3037 - val_loss: 10.4960 - val_mae: 2.4141\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2908 - mae: 1.3061 - val_loss: 10.2328 - val_mae: 2.3836\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3485 - mae: 1.3169 - val_loss: 10.0995 - val_mae: 2.3909\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2854 - mae: 1.3224 - val_loss: 9.8706 - val_mae: 2.3096\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2403 - mae: 1.2862 - val_loss: 10.2935 - val_mae: 2.4068\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3750 - mae: 1.2893 - val_loss: 9.8630 - val_mae: 2.2768\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.3151 - mae: 1.3050 - val_loss: 10.2983 - val_mae: 2.4087\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3761 - mae: 1.3035 - val_loss: 10.2034 - val_mae: 2.3635\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2370 - mae: 1.2619 - val_loss: 10.2237 - val_mae: 2.3622\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2796 - mae: 1.2514 - val_loss: 11.5255 - val_mae: 2.5736\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2380 - mae: 1.2921 - val_loss: 9.7769 - val_mae: 2.2481\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4192 - mae: 1.3076 - val_loss: 10.3899 - val_mae: 2.3937\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2890 - mae: 1.2829 - val_loss: 10.5502 - val_mae: 2.4243\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2412 - mae: 1.2923 - val_loss: 9.7219 - val_mae: 2.2124\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4307 - mae: 1.3038 - val_loss: 10.5734 - val_mae: 2.4185\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2208 - mae: 1.2686 - val_loss: 12.3743 - val_mae: 2.6539\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1917 - mae: 1.2958 - val_loss: 10.3128 - val_mae: 2.3784\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2454 - mae: 1.2694 - val_loss: 11.7141 - val_mae: 2.6118\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2597 - mae: 1.2759 - val_loss: 9.7598 - val_mae: 2.2280\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3161 - mae: 1.2929 - val_loss: 10.3691 - val_mae: 2.3598\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2077 - mae: 1.2993 - val_loss: 11.2428 - val_mae: 2.5247\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1723 - mae: 1.2836 - val_loss: 10.6783 - val_mae: 2.4409\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2311 - mae: 1.2808 - val_loss: 10.6109 - val_mae: 2.4404\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2234 - mae: 1.2861 - val_loss: 10.4920 - val_mae: 2.3985\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2421 - mae: 1.2716 - val_loss: 10.7506 - val_mae: 2.4360\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1750 - mae: 1.2750 - val_loss: 10.3488 - val_mae: 2.3539\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2001 - mae: 1.2785 - val_loss: 11.1613 - val_mae: 2.5079\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2404 - mae: 1.2729 - val_loss: 10.9755 - val_mae: 2.4666\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1214 - mae: 1.2554 - val_loss: 12.1730 - val_mae: 2.6188\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1902 - mae: 1.2920 - val_loss: 11.2422 - val_mae: 2.5104\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1932 - mae: 1.2630 - val_loss: 11.5565 - val_mae: 2.5649\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2657 - mae: 1.2958 - val_loss: 10.7354 - val_mae: 2.4524\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0845 - mae: 1.2504 - val_loss: 9.9379 - val_mae: 2.2517\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0077 - mae: 1.2681 - val_loss: 12.2174 - val_mae: 2.6291\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1950 - mae: 1.2789 - val_loss: 11.2958 - val_mae: 2.4958\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1945 - mae: 1.2835 - val_loss: 12.3758 - val_mae: 2.6726\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1297 - mae: 1.2776 - val_loss: 10.8780 - val_mae: 2.4486\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1963 - mae: 1.2741 - val_loss: 12.5473 - val_mae: 2.6881\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0993 - mae: 1.2661 - val_loss: 10.3477 - val_mae: 2.3333\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2238 - mae: 1.2729 - val_loss: 11.7220 - val_mae: 2.5790\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1457 - mae: 1.2598 - val_loss: 10.5721 - val_mae: 2.4066\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0434 - mae: 1.2217 - val_loss: 10.7458 - val_mae: 2.3908\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1807 - mae: 1.2610 - val_loss: 10.8901 - val_mae: 2.4397\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1810 - mae: 1.2578 - val_loss: 10.4579 - val_mae: 2.3577\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1302 - mae: 1.2469 - val_loss: 10.6854 - val_mae: 2.4488\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2532 - mae: 1.2617 - val_loss: 10.3451 - val_mae: 2.3209\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1082 - mae: 1.2341 - val_loss: 10.8799 - val_mae: 2.4564\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1770 - mae: 1.2499 - val_loss: 9.9504 - val_mae: 2.2427\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1368 - mae: 1.2733 - val_loss: 10.5758 - val_mae: 2.3994\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0209 - mae: 1.2281 - val_loss: 10.4768 - val_mae: 2.3939\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2336 - mae: 1.2806 - val_loss: 10.1412 - val_mae: 2.2992\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1585 - mae: 1.2655 - val_loss: 10.9212 - val_mae: 2.4271\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1077 - mae: 1.2628 - val_loss: 10.7210 - val_mae: 2.4142\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1838 - mae: 1.2560 - val_loss: 11.8987 - val_mae: 2.6106\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1138 - mae: 1.2264 - val_loss: 12.8899 - val_mae: 2.7417\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1445 - mae: 1.2612 - val_loss: 12.1926 - val_mae: 2.6162\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1298 - mae: 1.2638 - val_loss: 10.6572 - val_mae: 2.3667\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0774 - mae: 1.2474 - val_loss: 12.2364 - val_mae: 2.6492\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0156 - mae: 1.2473 - val_loss: 10.4322 - val_mae: 2.3338\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1808 - mae: 1.2558 - val_loss: 10.6037 - val_mae: 2.3913\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0653 - mae: 1.2245 - val_loss: 11.1411 - val_mae: 2.4612\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1831 - mae: 1.2379 - val_loss: 11.0347 - val_mae: 2.4538\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0709 - mae: 1.2468 - val_loss: 11.0262 - val_mae: 2.4499\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0973 - mae: 1.2584 - val_loss: 10.8764 - val_mae: 2.4397\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0390 - mae: 1.2265 - val_loss: 10.6988 - val_mae: 2.3978\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0775 - mae: 1.2620 - val_loss: 10.1665 - val_mae: 2.2579\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1839 - mae: 1.2429 - val_loss: 11.7027 - val_mae: 2.5692\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1126 - mae: 1.2294 - val_loss: 11.0016 - val_mae: 2.3989\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2220 - mae: 1.2586 - val_loss: 10.9863 - val_mae: 2.3747\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0451 - mae: 1.2348 - val_loss: 10.5396 - val_mae: 2.3627\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0813 - mae: 1.2381 - val_loss: 11.2930 - val_mae: 2.4692\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0542 - mae: 1.2514 - val_loss: 11.9315 - val_mae: 2.5566\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0091 - mae: 1.2407 - val_loss: 10.9865 - val_mae: 2.4289\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9563 - mae: 1.2194 - val_loss: 11.1693 - val_mae: 2.4669\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1603 - mae: 1.2336 - val_loss: 11.3681 - val_mae: 2.4937\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0239 - mae: 1.2310 - val_loss: 10.6984 - val_mae: 2.3762\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1777 - mae: 1.2450 - val_loss: 11.1662 - val_mae: 2.4720\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9902 - mae: 1.2393 - val_loss: 10.5264 - val_mae: 2.3268\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9525 - mae: 1.2096 - val_loss: 12.1854 - val_mae: 2.6031\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1236 - mae: 1.2747 - val_loss: 10.9456 - val_mae: 2.4459\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8929 - mae: 1.1922 - val_loss: 10.4907 - val_mae: 2.3156\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9958 - mae: 1.2298 - val_loss: 10.6905 - val_mae: 2.3767\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0037 - mae: 1.2416 - val_loss: 10.7126 - val_mae: 2.3968\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9652 - mae: 1.2105 - val_loss: 13.2448 - val_mae: 2.6898\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0204 - mae: 1.2383 - val_loss: 11.2269 - val_mae: 2.4820\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9577 - mae: 1.2416 - val_loss: 10.8264 - val_mae: 2.4000\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8524 - mae: 1.1925 - val_loss: 10.3903 - val_mae: 2.3284\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1991 - mae: 1.2246 - val_loss: 11.1367 - val_mae: 2.4771\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9861 - mae: 1.2430 - val_loss: 11.0848 - val_mae: 2.4157\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9296 - mae: 1.2249 - val_loss: 12.9017 - val_mae: 2.6716\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0521 - mae: 1.2483 - val_loss: 11.2066 - val_mae: 2.4478\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1406 - mae: 1.2220 - val_loss: 10.7273 - val_mae: 2.3515\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0451 - mae: 1.2331 - val_loss: 11.4215 - val_mae: 2.4913\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9974 - mae: 1.2274 - val_loss: 11.1280 - val_mae: 2.4407\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9705 - mae: 1.1926 - val_loss: 11.4044 - val_mae: 2.4460\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0371 - mae: 1.2154 - val_loss: 11.6092 - val_mae: 2.4980\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9758 - mae: 1.2099 - val_loss: 11.4736 - val_mae: 2.4716\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9875 - mae: 1.2212 - val_loss: 10.7181 - val_mae: 2.3919\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0644 - mae: 1.2162 - val_loss: 11.8792 - val_mae: 2.5883\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0359 - mae: 1.2316 - val_loss: 11.6860 - val_mae: 2.4863\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0480 - mae: 1.1957 - val_loss: 11.0087 - val_mae: 2.3845\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9890 - mae: 1.1836 - val_loss: 11.6683 - val_mae: 2.5156\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9725 - mae: 1.2127 - val_loss: 11.2785 - val_mae: 2.4711\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9211 - mae: 1.2130 - val_loss: 11.3013 - val_mae: 2.4648\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9817 - mae: 1.2303 - val_loss: 11.5735 - val_mae: 2.5263\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9526 - mae: 1.2163 - val_loss: 10.4184 - val_mae: 2.2953\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0062 - mae: 1.2167 - val_loss: 11.0615 - val_mae: 2.3999\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0070 - mae: 1.2197 - val_loss: 10.8546 - val_mae: 2.3965\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9485 - mae: 1.1995 - val_loss: 10.4794 - val_mae: 2.2972\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9487 - mae: 1.1892 - val_loss: 10.5680 - val_mae: 2.3532\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9778 - mae: 1.2104 - val_loss: 10.7305 - val_mae: 2.3238\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9784 - mae: 1.2198 - val_loss: 10.9418 - val_mae: 2.4197\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9726 - mae: 1.2105 - val_loss: 10.5573 - val_mae: 2.3203\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9267 - mae: 1.2130 - val_loss: 11.6073 - val_mae: 2.5375\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0826 - mae: 1.2030 - val_loss: 12.6944 - val_mae: 2.6664\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0608 - mae: 1.2275 - val_loss: 11.3154 - val_mae: 2.4923\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9005 - mae: 1.2055 - val_loss: 12.0014 - val_mae: 2.5533\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9737 - mae: 1.2053 - val_loss: 11.3716 - val_mae: 2.4893\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9634 - mae: 1.1911 - val_loss: 11.0158 - val_mae: 2.4101\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9276 - mae: 1.2049 - val_loss: 10.7679 - val_mae: 2.3615\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9390 - mae: 1.2029 - val_loss: 11.4832 - val_mae: 2.4870\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8602 - mae: 1.1982 - val_loss: 11.0427 - val_mae: 2.3674\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9049 - mae: 1.1886 - val_loss: 11.9887 - val_mae: 2.5686\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1729 - mae: 1.2052 - val_loss: 11.7378 - val_mae: 2.5526\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8934 - mae: 1.1900 - val_loss: 11.6263 - val_mae: 2.5024\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9247 - mae: 1.2064 - val_loss: 11.3833 - val_mae: 2.4747\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8702 - mae: 1.1800 - val_loss: 11.4383 - val_mae: 2.4792\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9518 - mae: 1.1945 - val_loss: 11.3155 - val_mae: 2.4848\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8723 - mae: 1.2001 - val_loss: 11.2644 - val_mae: 2.4242\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9401 - mae: 1.1767 - val_loss: 11.2123 - val_mae: 2.3922\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8723 - mae: 1.1954 - val_loss: 10.9637 - val_mae: 2.3931\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8688 - mae: 1.1735 - val_loss: 11.7603 - val_mae: 2.5456\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9785 - mae: 1.1979 - val_loss: 10.8592 - val_mae: 2.3507\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8745 - mae: 1.1657 - val_loss: 11.3295 - val_mae: 2.4398\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9335 - mae: 1.1912 - val_loss: 11.3504 - val_mae: 2.4491\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0423 - mae: 1.1954 - val_loss: 11.4875 - val_mae: 2.5196\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7599 - mae: 1.1788 - val_loss: 12.2375 - val_mae: 2.5668\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9996 - mae: 1.2087 - val_loss: 11.6794 - val_mae: 2.4856\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8196 - mae: 1.1793 - val_loss: 11.4843 - val_mae: 2.4814\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8575 - mae: 1.1751 - val_loss: 10.8849 - val_mae: 2.3689\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8722 - mae: 1.1945 - val_loss: 10.8496 - val_mae: 2.3980\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8691 - mae: 1.1761 - val_loss: 11.0586 - val_mae: 2.3952\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7991 - mae: 1.1958 - val_loss: 12.0762 - val_mae: 2.5665\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8266 - mae: 1.1735 - val_loss: 11.3813 - val_mae: 2.4787\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8998 - mae: 1.1583 - val_loss: 12.0829 - val_mae: 2.5113\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7971 - mae: 1.1853 - val_loss: 12.6055 - val_mae: 2.6447\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9041 - mae: 1.2152 - val_loss: 11.1551 - val_mae: 2.4144\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8163 - mae: 1.2023 - val_loss: 11.0058 - val_mae: 2.4373\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8298 - mae: 1.1625 - val_loss: 11.1713 - val_mae: 2.4489\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8717 - mae: 1.1829 - val_loss: 11.3748 - val_mae: 2.4574\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8750 - mae: 1.1730 - val_loss: 12.6223 - val_mae: 2.6523\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9478 - mae: 1.1979 - val_loss: 12.0408 - val_mae: 2.5481\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8526 - mae: 1.1628 - val_loss: 10.8943 - val_mae: 2.3570\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9635 - mae: 1.2274 - val_loss: 11.2577 - val_mae: 2.4182\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8351 - mae: 1.1814 - val_loss: 10.9369 - val_mae: 2.4043\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9235 - mae: 1.1839 - val_loss: 10.4923 - val_mae: 2.2884\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9518 - mae: 1.1859 - val_loss: 11.5261 - val_mae: 2.4998\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8964 - mae: 1.1868 - val_loss: 11.2251 - val_mae: 2.4387\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7986 - mae: 1.1925 - val_loss: 11.7888 - val_mae: 2.5014\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8850 - mae: 1.1614 - val_loss: 10.9459 - val_mae: 2.4135\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8355 - mae: 1.1593 - val_loss: 10.7348 - val_mae: 2.3501\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8779 - mae: 1.1694 - val_loss: 11.8586 - val_mae: 2.5270\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8094 - mae: 1.1753 - val_loss: 11.2298 - val_mae: 2.4224\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8849 - mae: 1.1724 - val_loss: 11.2467 - val_mae: 2.4087\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8916 - mae: 1.1891 - val_loss: 11.3371 - val_mae: 2.4251\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7396 - mae: 1.1502 - val_loss: 11.3180 - val_mae: 2.4420\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8727 - mae: 1.1703 - val_loss: 11.5032 - val_mae: 2.4745\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8200 - mae: 1.1547 - val_loss: 11.1020 - val_mae: 2.3860\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0693 - mae: 1.1690 - val_loss: 12.1757 - val_mae: 2.5932\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7849 - mae: 1.2020 - val_loss: 10.8015 - val_mae: 2.3684\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9675 - mae: 1.1849 - val_loss: 11.2041 - val_mae: 2.4195\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8312 - mae: 1.2012 - val_loss: 11.1635 - val_mae: 2.4334\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8447 - mae: 1.1576 - val_loss: 12.3311 - val_mae: 2.6000\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7192 - mae: 1.1580 - val_loss: 10.7618 - val_mae: 2.3289\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8520 - mae: 1.1771 - val_loss: 11.4385 - val_mae: 2.4524\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8321 - mae: 1.1738 - val_loss: 11.7583 - val_mae: 2.4816\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7472 - mae: 1.1359 - val_loss: 11.3591 - val_mae: 2.4328\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7743 - mae: 1.1473 - val_loss: 12.4643 - val_mae: 2.6036\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5961 - mae: 1.1806 - val_loss: 13.0867 - val_mae: 2.6693\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7665 - mae: 1.1370 - val_loss: 11.7741 - val_mae: 2.4940\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9634 - mae: 1.1708 - val_loss: 11.1692 - val_mae: 2.3613\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8176 - mae: 1.1438 - val_loss: 12.1044 - val_mae: 2.6056\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7803 - mae: 1.1579 - val_loss: 11.4801 - val_mae: 2.4934\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7929 - mae: 1.1633 - val_loss: 11.5870 - val_mae: 2.4752\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7617 - mae: 1.0985 - val_loss: 12.1580 - val_mae: 2.5406\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8077 - mae: 1.1484 - val_loss: 11.6595 - val_mae: 2.5056\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7973 - mae: 1.1567 - val_loss: 10.6631 - val_mae: 2.3197\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7805 - mae: 1.1901 - val_loss: 11.3925 - val_mae: 2.4363\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8977 - mae: 1.1588 - val_loss: 11.8703 - val_mae: 2.5534\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8772 - mae: 1.1782 - val_loss: 11.8856 - val_mae: 2.5292\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7650 - mae: 1.1515 - val_loss: 12.4171 - val_mae: 2.6186\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7207 - mae: 1.1705 - val_loss: 12.4101 - val_mae: 2.5799\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7965 - mae: 1.1476 - val_loss: 12.2526 - val_mae: 2.5210\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9819 - mae: 1.1399 - val_loss: 11.1579 - val_mae: 2.4022\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7477 - mae: 1.1488 - val_loss: 11.6164 - val_mae: 2.4942\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7565 - mae: 1.1838 - val_loss: 11.2285 - val_mae: 2.4157\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7469 - mae: 1.1492 - val_loss: 11.2215 - val_mae: 2.4519\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7417 - mae: 1.1604 - val_loss: 11.3029 - val_mae: 2.3997\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7068 - mae: 1.1531 - val_loss: 11.9244 - val_mae: 2.4854\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7578 - mae: 1.1718 - val_loss: 11.8109 - val_mae: 2.5087\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6794 - mae: 1.1421 - val_loss: 10.8835 - val_mae: 2.3504\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7561 - mae: 1.1515 - val_loss: 11.4914 - val_mae: 2.4496\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7624 - mae: 1.1591 - val_loss: 11.2436 - val_mae: 2.3855\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8350 - mae: 1.1679 - val_loss: 12.2659 - val_mae: 2.5195\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6838 - mae: 1.1351 - val_loss: 12.7199 - val_mae: 2.5778\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8318 - mae: 1.1648 - val_loss: 12.2593 - val_mae: 2.5649\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7284 - mae: 1.1578 - val_loss: 11.3147 - val_mae: 2.4287\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6375 - mae: 1.1182 - val_loss: 11.4186 - val_mae: 2.4599\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9514 - mae: 1.1583 - val_loss: 11.3173 - val_mae: 2.4125\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7370 - mae: 1.1449 - val_loss: 12.0221 - val_mae: 2.5082\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6765 - mae: 1.1447 - val_loss: 12.8156 - val_mae: 2.6101\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7485 - mae: 1.1536 - val_loss: 11.2555 - val_mae: 2.4127\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7264 - mae: 1.1556 - val_loss: 11.1052 - val_mae: 2.4059\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8405 - mae: 1.1530 - val_loss: 11.2735 - val_mae: 2.3904\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8013 - mae: 1.1457 - val_loss: 11.2755 - val_mae: 2.3909\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7410 - mae: 1.1426 - val_loss: 13.0615 - val_mae: 2.6378\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6571 - mae: 1.1646 - val_loss: 12.2457 - val_mae: 2.5152\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5995 - mae: 1.0979 - val_loss: 11.9115 - val_mae: 2.4865\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7112 - mae: 1.1618 - val_loss: 12.0072 - val_mae: 2.5563\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7411 - mae: 1.1469 - val_loss: 12.1539 - val_mae: 2.5042\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6895 - mae: 1.1566 - val_loss: 11.3272 - val_mae: 2.4048\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7287 - mae: 1.1197 - val_loss: 11.3274 - val_mae: 2.4267\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6628 - mae: 1.1268 - val_loss: 12.6050 - val_mae: 2.6060\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7275 - mae: 1.1612 - val_loss: 11.5885 - val_mae: 2.4619\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7472 - mae: 1.1442 - val_loss: 12.9118 - val_mae: 2.6105\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6826 - mae: 1.1316 - val_loss: 11.2972 - val_mae: 2.4266\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7006 - mae: 1.1406 - val_loss: 12.9848 - val_mae: 2.6360\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7060 - mae: 1.1330 - val_loss: 12.5500 - val_mae: 2.5661\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6746 - mae: 1.1331 - val_loss: 12.4557 - val_mae: 2.5713\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5638 - mae: 1.1265 - val_loss: 12.1366 - val_mae: 2.5093\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7480 - mae: 1.1107 - val_loss: 11.2616 - val_mae: 2.4186\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8324 - mae: 1.1335 - val_loss: 11.1915 - val_mae: 2.3767\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6915 - mae: 1.1509 - val_loss: 11.3637 - val_mae: 2.3834\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6331 - mae: 1.1374 - val_loss: 11.7445 - val_mae: 2.4622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0mfozSscm2u",
        "colab_type": "code",
        "outputId": "78611f51-db90-47c4-8355-e8721c53cce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = historyc.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg0o2OdfcrJr",
        "colab_type": "code",
        "outputId": "b1187bab-638c-43b7-a6af-882d4cd34225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "mae = history_dict['mae']\n",
        "val_mae = history_dict['val_mae']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(mae) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JieE9PAcrGL",
        "colab_type": "code",
        "outputId": "7a1c003a-9328-439f-b286-1bac5ca5966b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeWMVfDdqsTg",
        "colab_type": "code",
        "outputId": "e4d2e609-a38e-4828-e552-8589007e81d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "\n",
        "plt.plot(epochs, mae, 'r', label='Training mae')\n",
        "plt.title('Training MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfBUlEQVR4nO3df3RV5Z3v8fc3PwiERIGA/BQD1UqxStCgIK4BO1fFWlur9gfX28Fbp1qX9Qe3vbZ2bGtX565lZ+5tvdTajo4tOuN0nI71R62XKlRq1VYMQikKFmqDDfIjRAhECCThe/94dg6HEAiB8yM5z+e11lln72fvs/ezD+HzPPs5++xj7o6IiMSjKN8VEBGR3FLwi4hERsEvIhIZBb+ISGQU/CIikVHwi4hERsEv0TGz/2dm8zK9rkh/oeCXfsHMWtIe+81sT9r8Nb3Zlrtf6u4PZXrd3jCz2WbmZvZ4l/IpSfnSLuVmZm+Z2RvdbGupmbV2eY9+nuk6S+EoyXcFRI6Gu1d0TptZPfC37r6463pmVuLu7bms23FoBGaYWZW7NyVl84A/drPuXwEnASVmNs3dX+2y/Avu/s9ZrKsUEPX4pV9Les4NZvZlM9sM/NjMhprZ02bWaGbbk+lxaa9ZamZ/m0xfa2Yvmtn/Ttb9s5ldeozrTjCzF8xsl5ktNrPvm9m/HqH6+4AngE8nry8GPgU80s2684AngWeSaZFjpuCXQjAKGAacAlxP+Lv+cTI/HtgD3HuE158HvAkMB/4BeNDM7BjW/TdgGVAF3AV85ijq/jDwN8n0JcBq4J30FcysHLia0CA8AnzazAYcxbZFuqXgl0KwH/iGu+919z3u3uTuj7n7bnffBfwvYNYRXr/B3R9w9w7gIWA0MLI365rZeGAa8HV33+fuLwJP9VRxd38ZGGZmpxMagIe7We1KYC/wLPALoBS4rMs6C8xsR9rjWz3tW+Kl4JdC0OjurZ0zZlZuZv9kZhvMbCfwAjAkGUrpzubOCXffnUxW9HLdMcC7aWUAfznK+v8L8AXgQuDxbpbPA/7D3duT43yMQ4d7bnH3IWmPrx3lviVC+nBXCkHXW8x+ETgdOM/dN5tZDbACONzwTSZsIvTcy9PC/+SjfO2/AOuBh919d/ooU/LZxIeAc83sqqS4HBhoZsPdfVtmqi8xUY9fClElYVx/h5kNA76R7R26+wagDrjLzAaY2Qzg8qN87Z8JQ1F/183izxCu8jkdqEke7wcagLkZqLpESMEvhegeYBCwDfgdsChH+70GmAE0AX8PPEoYm++Ru7/o7u90s2gecJ+7b05/AD/k4OGee7tcx7/8+A5FCpnph1hEssPMHgXWunvWzzhEekM9fpEMMbNpZvY+MysysznAxwjX6Yv0KfpwVyRzRgE/I1zH3wDc6O4r8lslkUNpqEdEJDIa6hERiUy/GOoZPny4V1dX57saIiL9yvLly7e5+4iu5f0i+Kurq6mrq8t3NURE+hUz29BduYZ6REQio+AXEYmMgl9EJDL9YoxfRPqWtrY2GhoaaG1t7XllybqBAwcybtw4SktLj2p9Bb+I9FpDQwOVlZVUV1dz+N+skVxwd5qammhoaGDChAlH9RoN9YhIr7W2tlJVVaXQ7wPMjKqqql6dfSn4ReSYKPT7jt7+WxR28D/9NNx9d75rISLSpxR28C9aBP/4j/muhYhkWFNTEzU1NdTU1DBq1CjGjh2bmt+3b98RX1tXV8ctt9zS4z7OP//8TFW3zynsD3fLy2H37p7XE5F+paqqipUrVwJw1113UVFRwZe+9KXU8vb2dkpKuo+32tpaamtre9zHyy+/nJnK9kGF3eMfNAhaW0F3IBUpeNdeey2f//znOe+887j99ttZtmwZM2bMYOrUqZx//vm8+eabACxdupSPfOQjQGg0PvvZzzJ79mwmTpzIggULUturqKhIrT979myuvvpqJk2axDXXXEPnXY2feeYZJk2axDnnnMMtt9yS2m66hQsXcsUVV3DRRRdRXV3Nvffey3e+8x2mTp3K9OnTeffddwF44IEHmDZtGlOmTOGqq65id9JpbWxs5KqrrmLatGlMmzaNl1566bjfq8Lu8Q8aFJ5bWw9Mi0hm3XYbJL3vjKmpgXvu6fXLGhoaePnllykuLmbnzp385je/oaSkhMWLF/PVr36Vxx577JDXrF27lueff55du3Zx+umnc+ONNx5yPfyKFSt4/fXXGTNmDDNnzuSll16itraWG264gRdeeIEJEyYwd+7hfwJ59erVrFixgtbWVk499VS+/e1vs2LFCubPn8/DDz/MbbfdxpVXXsnnPvc5AO68804efPBBbr75Zm699Vbmz5/PBRdcwNtvv80ll1zCmjVrev3epIsj+HfvVvCLROATn/gExcXFADQ3NzNv3jzWrVuHmdHW1tbtay677DLKysooKyvjpJNOYsuWLYwbN+6gdc4999xUWU1NDfX19VRUVDBx4sTUtfNz587l/vvv73YfF154IZWVlVRWVnLiiSdy+eWXA3DmmWeyatUqIDQOd955Jzt27KClpYVLLrkEgMWLF/PGG2+ktrVz505aWlpSZyTHorCDv7w8PO/Zk996iBSyY+iZZ8vgwYNT01/72te48MILefzxx6mvr2f27NndvqasrCw1XVxcTHt7+zGtcyTpry8qKkrNFxUVpbZ17bXX8sQTTzBlyhQWLlzI0qVLAdi/fz+/+93vGDhwYK/2eSSFP8YPCn6RCDU3NzN27FggjLNn2umnn85bb71FfX09AI8++uhxbW/Xrl2MHj2atrY2HnnkkVT5xRdfzPe+973U/MoMDKsp+EWkIN1+++3ccccdTJ06tdc99KMxaNAg7rvvPubMmcM555yTGsY5Vt/61rc477zzmDlzJpMmTUqVL1iwgLq6Os466ywmT57MD3/4w+Oue7/4zd3a2lo/ph9ieeYZuOwy+O1vYfr0zFdMJFJr1qzhAx/4QL6rkXedY+3uzk033cRpp53G/Pnz81KX7v5NzGy5ux9y7Wph9/g1xi8iWfTAAw9QU1PDGWecQXNzMzfccEO+q3RUCvvDXQ31iEgWzZ8/P289/ONR2D1+Bb9I1vSHYeJY9PbforCDv3OoR7dtEMmogQMH0tTUpPDvAzrvx9+byz011CMivTZu3DgaGhpobGzMd1WEA7/AdbQU/CLSa6WlpUf9a0/S9xT2UI+CX0TkEIUd/J1jXhrjFxFJKezgNwvh34vfohQRKXSFHfwAAwZAD7/IIyISEwW/iEhkCj/4y8oU/CIiaQo/+AcMgL17810LEZE+I2vBb2Ynm9nzZvaGmb1uZrcm5cPM7DkzW5c8D81WHQAN9YiIdJHNHn878EV3nwxMB24ys8nAV4Al7n4asCSZzx4N9YiIHCRrwe/um9z9tWR6F7AGGAt8DHgoWe0h4Ips1QFQj19EpIucjPGbWTUwFXgFGOnum5JFm4GRh3nN9WZWZ2Z1x3U/EI3xi4gcJOvBb2YVwGPAbe6+M32Zh1v7dXt7P3e/391r3b12xIgRx14B9fhFRA6S1eA3s1JC6D/i7j9LireY2ehk+WhgazbroDF+EZGDZfOqHgMeBNa4+3fSFj0FzEum5wFPZqsOgHr8IiJdZPO2zDOBzwB/MLOVSdlXgbuB/zCz64ANwCezWAeN8YuIdJG14Hf3FwE7zOK/ztZ+D6GhHhGRg8TxzV0Fv4hIioJfRCQyhR/8ZWUa4xcRSVP4wa8ev4jIQRT8IiKRiSP429rAu/2CsIhIdAo/+MvKwrN6/SIiQAzBP2BAeFbwi4gACn4RkegUfvB3DvXokk4RESCG4FePX0TkIAp+EZHIKPhFRCJT+MGvMX4RkYMUfvCrxy8ichAFv4hIZAo/+PXNXRGRgxR+8Hf2+DXGLyICxBT86vGLiAAKfhGR6BR+8GuMX0TkIIUf/BrjFxE5SDzBrx6/iAgQQ/BrqEdE5CCFH/wa6hEROUjhB39paXhWj19EBIgh+IuLw0PBLyICxBD8EMb5FfwiIkAswT9ggMb4RUQS8QS/evwiIkAswa+hHhGRlDiCXz1+EZGUeIJfY/wiIkBMwa8ev4gIEEvwa4xfRCQljuDXUI+ISErWgt/MfmRmW81sdVrZXWa20cxWJo8PZ2v/Bykthba2nOxKRKSvy2aPfyEwp5vy77p7TfJ4Jov7P0DBLyKSkrXgd/cXgHeztf1eUfCLiKTkY4z/C2a2KhkKGpqTPSr4RURSch38PwDeB9QAm4D/c7gVzex6M6szs7rGxsbj26uCX0QkJafB7+5b3L3D3fcDDwDnHmHd+9291t1rR4wYcXw7VvCLiKTkNPjNbHTa7MeB1YdbN6NKShT8IiKJkmxt2Mx+AswGhptZA/ANYLaZ1QAO1AM3ZGv/Bykthfb2nOxKRKSvy1rwu/vcboofzNb+jkhDPSIiKXF8c1fBLyKSouAXEYmMgl9EJDIKfhGRyMQT/Pv3h4eISOTiCX5Qr19EhFiCvyS5alXBLyISSfCrxy8ikqLgFxGJTFzBr9s2iIhEFvzq8YuIKPhFRGKj4BcRiYyCX0QkMgp+EZHIHDH4zeyEIywbn/nqZIm+wCUiktJTj39p54SZLemy7ImM1yZb1OMXEUnpKfgtbXrYEZb1bQp+EZGUnoLfDzPd3XzfpeAXEUnp6Td3TzKz/0Ho3XdOk8yPyGrNMknBLyKS0lPwPwBUdjMN8M9ZqVE26JYNIiIpRwx+d//m4ZaZ2bTMVydL1OMXEUnpqcd/EDObDMxNHjuA2mxUKuMU/CIiKT0Gv5lVcyDs24BTgFp3r89mxTJKwS8iktLTF7h+C/yC0EBc5e7nALv6VeiDvsAlIpKmp8s5txA+0B3Jgat4+s9lnJ3U4xcRSTli8Lv7FcCZwHLgLjP7MzDUzM7NReUyRsEvIpLS4xi/uzcDPwZ+bGYjgU8C3zWz8e5+crYrmBEKfhGRlF7dndPdt7j799x9JnBBluqUeQp+EZGUI/b4zeypHl7/0QzWJXsU/CIiKT0N9cwA/gL8BHiF/nRjtnTFxeFZ39wVEekx+EcBFxGu4f+vhEs7f+Lur2e7YhllFnr96vGLiPR4VU+Huy9y93nAdGA9sNTMvpCT2mWSgl9EBDi6b+6WAZcRev3VwALg8exWKwtKShT8IiL0/OHuw8AHgWeAb7r76pzUKhvU4xcRAXru8f834D3gVuAWs9Rnuwa4ux/2N3n7HAW/iAjQ822Ze3Wdf5+m4BcRAXr5Ba7eMLMfmdlWM1udVjbMzJ4zs3XJ89Bs7f8QCn4RESCLwQ8sBOZ0KfsKsMTdTwOWJPO5oeAXEQGyGPzu/gLwbpfijwEPJdMPAVdka/+HUPCLiADZ7fF3Z6S7b0qmNxNu99wtM7vezOrMrK6xsfH496zgFxEBch/8Ke7uHOHe/u5+v7vXunvtiBEjDrfa0Sst1S0bRETIffBvMbPRAMnz1pztWV/gEhEBch/8TwHzkul5wJM527OGekREgOxezvkT4LfA6WbWYGbXAXcDF5nZOuC/JPO5oeAXEQGO4l49x8rd5x5m0V9na59HpOAXEQHy+OFuzin4RUQABb+ISHQU/CIikVHwi4hERsEvIhIZBb+ISGTiCf6SEt2yQUSEmIJfPX4REUDBLyISHQW/iEhk4gr+jg7ww94JWkQkCnEFP6jXLyLRU/CLiEQmnuAvSW5Eqks6RSRy8QS/evwiIoCCX0QkOgp+EZHIKPhFRCKj4BcRiYyCX0QkMvEEvy7nFBEBYgp+9fhFRAAFv4hIdBT8IiKRUfCLiERGwS8iEhkFv4hIZOIJfl3OKSICxBT86vGLiAAKfhGR6Cj4RUQio+AXEYmMgl9EJDIKfhGRyMQT/LqcU0QEiCn41eMXEQEU/CIi0SnJx07NrB7YBXQA7e5em/WdFhWFh4JfRCKXl+BPXOju23K6x9JSBb+IRC+eoR5Q8IuIkL/gd+BZM1tuZtd3t4KZXW9mdWZW19jYmJm9KvhFRPIW/Be4+9nApcBNZvZXXVdw9/vdvdbda0eMGJGZvZaXw+7dmdmWiEg/lZfgd/eNyfNW4HHg3JzsuKICWlpysisRkb4q58FvZoPNrLJzGrgYWJ2TnVdWwq5dOdmViEhflY+rekYCj5tZ5/7/zd0X5WTP6vGLiOQ++N39LWBKrvcLhODfuDEvuxYR6SviupxTQz0iIpEFv4Z6REQiC371+EVEIgv+igp47z3Yvz/fNRERyZu4gr+yMjzrS1wiErG4gr+iIjxruEdEIhZn8OsDXhGJWFzBP3RoeN6W27tBi4j0JXEF/8SJ4fmtt/JbDxGRPIor+CdMADNYvz7fNRERyZu4gn/gQDj5ZPjTn/JdExGRvIkr+AFOPRXeeCPftRARyZv4gn/WLHjtNdi0Kd81ERHJi/iC/8orwR1++tN810REJC/iC/4PfhCmTYP77tOtG0QkSvEFP8DNN8Obb8LixfmuiYhIzsUZ/J/8JIwcCXfcAXv35rs2IiI5FWfwl5XBD34QPuRdsCDftRERyak4gx/g4x+Hyy6Dr38dXnwx37UREcmZeIMfYOFCOOUUuPxyWL0637UREcmJuIN/+HD45S9h0CCYMwd+/et810hEJOviDn4IPf5Fi8L07Nlw8cWwYkW41l9EpACV5LsCfcJZZ8G6deHa/rvvhrPPDlf9TJ8OY8eGx+jRcNpp4Sxh4kQoLg4PEZF+xrwf9Gxra2u9rq4uNzvbvh3uuQeeeAJ27oT6+u7XKysLZwvDh4e7fnb+kPvOndDeHr4oVlwclu3bF84gxoyB6moYMSJMl5SE12zeDOPGhZvImeXmOEWk4JnZcnevPaRcwd+Dd94JIb99O/zqV+HH2v/zP8PN3lpbobERli2D0lKoqgoNQFMTbNx45G8GDxgQgr+9PTQMEBqKYcNCw1BfD+9/P0ydCg0NUFQEkyeH7x20toZ19+6Fiy4KjciePeEHZkpLw/43bYLx4+HSS8PZTElJ2O64cTB48IF979kTngcNCg2PiBQMBX82tbeHIO7srbtDRwc0N4cwLimBE04IAf7227B1a7iKyCz0+KdPh5deCuuVlITGpqoKNmyA3/8+nFn8+c+wY0cI7YqK0OAMHHhsPxw/YEAYympoOPBZRmVlaBhGjgz7GTIkNCIlJWGfK1eGhmTo0NAIVVWFR3V1OKaSktAAtbZCbe2B7b79Nrz7Lpx5JrS1hW0OGxa2tXZt2NaECaERGzs2bEdEMkLB39/t3x+CE8IZSEdHKFu7Nvy+QGVlGHYqLQ2P114L83/8YwjU1tYQwps2hQZn8+YQuCecEJatXx+Gqf7wh/CZR3NzaFSam0MDMXNmaJA2bYJRo0KYb916oE6ZMmRI2P/27WHblZWhMWhrC2cn7qHR6DxLOvHEcBY2eXL4HKalJbw3mzeH9YcPD43L9u3h7GnMmNAYDxsWGrF9+8I67mE7u3aF18+aFbY9YEDY5p49Yf6dd0Jjlz4kt29feI2G6qSPUfDLsXPvPtDa28PwV00NlJfDli1hyOjnPw+Nz44dodGZNStcKWUWevaNjaEBOfPMsN7LL8Ozz4ZAr6oKZznDhoXGZdkymDQpLNu9OwRwUVFoCPbuDWda+/eHhmvfvrAPsxDqncNu7mH6WG7FXVp6aOM2ZEiow/jx4Zh37Aj1gjCUdtZZoXEZOTKUNzaGs7T33gv1/cAHQr0uughWrQrlRUUHzsRGjgwNUHt7aJiHDAmNTlNTGLYbNCg0Plu3hkZxyJDwfp18chhidA+N4IYNoW7t7WH9qqoDDXfn50/r1oXpjo5wZldeHp7LysJ0U1N4D158MdS3re3AhQ2lpaGzsG9fOFssLw/HAWF7nRc/dHSE8lw3iof7u42Igl/6H/cQmieddHTr7twZAnb//hCIXf/Tr18fzgQqKkKj4h4Cae/eEI7l5SGwd+4Mgd7eHs52Ro0Kwdo5bLd8eQjHt98OjVLn5yVbtoTtbdgQXrN1awjQUaNCuA8cGJZt3x5Cvr4+1KW8PMw3NBxc385A7i9OOCE8du06cBa2b1845qKi8D69//2hAd+8ObynGzeGRmno0PDvMHhweOzYERrAlpYw3/n6lpZwhlpZGcrb2g68ZtGisM8xY8K/9UsvwfnnH2iAzz47vM/btoUz2VNOCdtcsiRsf8aMsO0xY8J7v3lz6LgMGhQa+YaG0ACmN7SlpaFTU10djnnkyPC8e3fY9ujR4d+ws7NQVBTen84h2uLiUOcVK+B97wv1GzMmnIUuXx7+lmtqQh2OgYJfpC/p6Djw+U1VVSjbty8EWUdHaBDMDgy3dfbcx48PDVNLS7i8uL09LPvLX+DVV0N4FRXB66+HXviWLXDJJWHIb+3aMNzV1BQa1G3bQq9/y5YQZE1NBz6r6hxqGz48nCW88EII2ylTQoO5dm2o98SJob4dHfDKKyGghg0L67z6amgIPvjBsM2OjjCUWF4ejnvbtjDd3Bzq0zls99574f1oagqBvn17eB927w7H3NIS3qv9+8Ox7tkTXjNrVgh7s7CstTU0uhUVYXudv7U9YMCBoUIIZ2nt7SHoi4r63u3an3wSPvrRY3qpgl9EClNHRwj5wYMPDCt1lqdfLNDUFEK/sjI0FM3NYd2RI8PyTZtCY7ZqVThT67xoA+Chh8KXO2fPDuXvvhsaqz17whV+LS1h2++8ExqbpqawjVWrwhlrWVloDPfvD49f/CI0oqNHh0a083Mt9wOfpZ1xRjhLnDUrNKbHQMEvIhKZwwW/btkgIhIZBb+ISGQU/CIikVHwi4hERsEvIhIZBb+ISGQU/CIikVHwi4hEpl98gcvMGoENx/jy4cC2DFanP9Axx0HHHIfjOeZT3H1E18J+EfzHw8zquvvmWiHTMcdBxxyHbByzhnpERCKj4BcRiUwMwX9/viuQBzrmOOiY45DxYy74MX4RETlYDD1+ERFJo+AXEYlMwQa/mc0xszfNbL2ZfSXf9ckUM/uRmW01s9VpZcPM7DkzW5c8D03KzcwWJO/BKjM7O381P3ZmdrKZPW9mb5jZ62Z2a1JesMdtZgPNbJmZ/T455m8m5RPM7JXk2B41swFJeVkyvz5ZXp3P+h8PMys2sxVm9nQyX9DHbGb1ZvYHM1tpZnVJWVb/tgsy+M2sGPg+cCkwGZhrZpPzW6uMWQjM6VL2FWCJu58GLEnmIRz/acnjeuAHOapjprUDX3T3ycB04Kbk37OQj3sv8CF3nwLUAHPMbDrwbeC77n4qsB24Lln/OmB7Uv7dZL3+6lZgTdp8DMd8obvXpF2vn92/bXcvuAcwA/hl2vwdwB35rlcGj68aWJ02/yYwOpkeDbyZTP8TMLe79frzA3gSuCiW4wbKgdeA8wjf4CxJylN/58AvgRnJdEmynuW77sdwrOOSoPsQ8DRgERxzPTC8S1lW/7YLsscPjAX+kjbfkJQVqpHuvimZ3gwkvx5deO9Dcjo/FXiFAj/uZMhjJbAVeA74E7DD3duTVdKPK3XMyfJmoCq3Nc6Ie4Dbgf3JfBWFf8wOPGtmy83s+qQsq3/bJT2vIv2Ju7uZFeQ1umZWATwG3ObuO80stawQj9vdO4AaMxsCPA5MynOVssrMPgJsdfflZjY73/XJoQvcfaOZnQQ8Z2Zr0xdm42+7UHv8G4GT0+bHJWWFaouZjQZInrcm5QXzPphZKSH0H3H3nyXFBX/cAO6+A3ieMMwxxMw6O2zpx5U65mT5iUBTjqt6vGYCHzWzeuDfCcM9/5fCPmbcfWPyvJXQwJ9Llv+2CzX4XwVOS64GGAB8Gngqz3XKpqeAecn0PMIYeGf53yRXAkwHmtNOH/sNC137B4E17v6dtEUFe9xmNiLp6WNmgwifaawhNABXJ6t1PebO9+Jq4FeeDAL3F+5+h7uPc/dqwv/ZX7n7NRTwMZvZYDOr7JwGLgZWk+2/7Xx/sJHFD0w+DPyRMC76d/muTwaP6yfAJqCNML53HWFccwmwDlgMDEvWNcLVTX8C/gDU5rv+x3jMFxDGQVcBK5PHhwv5uIGzgBXJMa8Gvp6UTwSWAeuBnwJlSfnAZH59snxivo/hOI9/NvB0oR9zcmy/Tx6vd2ZVtv+2dcsGEZHIFOpQj4iIHIaCX0QkMgp+EZHIKPhFRCKj4BcRiYyCX6JmZh3JXRE7Hxm7k6uZVVvaXVRF+grdskFit8fda/JdCZFcUo9fpBvJPdL/IblP+jIzOzUprzazXyX3Ql9iZuOT8pFm9nhy//zfm9n5yaaKzeyB5J76zybfwsXMbrHw+wKrzOzf83SYEikFv8RuUJehnk+lLWt29zOBewl3jQT4HvCQu58FPAIsSMoXAL/2cP/8swnfwoRw3/Tvu/sZwA7gqqT8K8DUZDufz9bBiXRH39yVqJlZi7tXdFNeT/ghlLeSG8RtdvcqM9tGuP95W1K+yd2Hm1kjMM7d96Ztoxp4zsOPaWBmXwZK3f3vzWwR0AI8ATzh7i1ZPlSRFPX4RQ7PDzPdG3vTpjs48LnaZYR7rpwNvJp290mRrFPwixzep9Kef5tMv0y4cyTANcBvkuklwI2Q+gGVEw+3UTMrAk529+eBLxNuJ3zIWYdItqiXIbEblPzKVadF7t55SedQM1tF6LXPTcpuBn5sZv8TaAT+e1J+K3C/mV1H6NnfSLiLaneKgX9NGgcDFni4575ITmiMX6QbyRh/rbtvy3ddRDJNQz0iIpFRj19EJDLq8YuIREbBLyISGQW/iEhkFPwiIpFR8IuIROb/AyWxOf2NtUIKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6x3KUeaqr20",
        "colab_type": "code",
        "outputId": "f4b7a88c-226f-4531-f73d-ce4f86d8bfb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs, val_mae, 'b', label='Validation mae')\n",
        "plt.title('Validation MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y70rNXYuxI6M",
        "colab_type": "text"
      },
      "source": [
        "#6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9xHRrwCeCOP",
        "colab_type": "code",
        "outputId": "e50d98e2-1302-4e5e-9979-6cc8fa67113c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modelc.fit(Xtrain, ytrain,\n",
        "          epochs=15, batch_size=8, verbose=0)\n",
        "test_mse_score, test_mae_score = modelc.evaluate(Xtest, ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 969us/step - loss: 9.1743 - mae: 2.0432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACNE1N1meN3C",
        "colab_type": "code",
        "outputId": "33816a48-09c0-43d5-e6a5-ed7b75f0e098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0431718826293945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAhbs9BKehVy",
        "colab_type": "code",
        "outputId": "17818273-90d2-4b37-e9b1-a893e280b659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modelc.fit(Xtrain, ytrain,\n",
        "          epochs=20, batch_size=8, verbose=0)\n",
        "test_mse_score, test_mae_score = modelc.evaluate(Xtest, ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 1ms/step - loss: 8.8802 - mae: 1.9626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZs2w0CGq-ux",
        "colab_type": "code",
        "outputId": "2a020888-3072-4e21-d10d-c146d7598868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9626014232635498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sswR4oRQrh0_",
        "colab_type": "code",
        "outputId": "9b05e019-b0f6-4760-c126-a61408bfcb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modelc.fit(Xtrain, ytrain,\n",
        "          epochs=18, batch_size=8, verbose=0)\n",
        "test_mse_score, test_mae_score = modelc.evaluate(Xtest, ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 917us/step - loss: 9.4565 - mae: 1.9938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIWNM-iOswhE",
        "colab_type": "code",
        "outputId": "bf767039-6997-4e04-b1eb-d5c8040c61de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.993788719177246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}